{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('financial_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = ['months_employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['personal_account_months']=(dataset.personal_account_m + (dataset.personal_account_y * 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal_account_m</th>\n",
       "      <th>personal_account_y</th>\n",
       "      <th>personal_account_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personal_account_m  personal_account_y  personal_account_months\n",
       "0                   6                   2                       30\n",
       "1                   2                   7                       86\n",
       "2                   7                   1                       19\n",
       "3                   2                   7                       86\n",
       "4                   2                   8                       98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['personal_account_m','personal_account_y','personal_account_months']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(columns=['personal_account_m','personal_account_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'age', 'home_owner', 'income', 'years_employed',\n",
       "       'current_address_year', 'has_debt', 'amount_requested', 'risk_score',\n",
       "       'risk_score_2', 'risk_score_3', 'risk_score_4', 'risk_score_5',\n",
       "       'ext_quality_score', 'ext_quality_score_2', 'inquiries_last_month',\n",
       "       'e_signed', 'personal_account_months', 'pay_schedule_bi-weekly',\n",
       "       'pay_schedule_monthly', 'pay_schedule_semi-monthly',\n",
       "       'pay_schedule_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(columns=['pay_schedule_semi-monthly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Extra Columns ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dataset['e_signed']\n",
    "users = dataset['entry_id']\n",
    "dataset=dataset.drop(columns = [\"e_signed\",\"entry_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train and Test Set ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset,\n",
    "                                                    response,\n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = pd.DataFrame(sc_X.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.index = X_train.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, penalty= 'l2')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame([['Linear Regression(Lasso)',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Linear Regression(Lasso)  0.563372   0.577844  0.700726   0.63338\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Linear Regression(Lasso)  0.563372   0.577844  0.700726  0.633380\n",
      "1              SVM (Linear)  0.568398   0.578536  0.729772  0.645413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel='linear')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "model_results=pd.DataFrame([['SVM (Linear)',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "results= results.append(model_results,ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Linear Regression(Lasso)  0.563372   0.577844  0.700726  0.633380\n",
      "1              SVM (Linear)  0.568398   0.578536  0.729772  0.645413\n",
      "2                 SVM (rbf)  0.592686   0.607519  0.687241  0.644926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel='rbf')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "model_results1=pd.DataFrame([['SVM (rbf)',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "results= results.append(model_results1,ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Linear Regression(Lasso)  0.563372   0.577844  0.700726  0.633380\n",
      "1              SVM (Linear)  0.568398   0.578536  0.729772  0.645413\n",
      "2                 SVM (rbf)  0.592686   0.607519  0.687241  0.644926\n",
      "3       Random Forest n=100  0.623953   0.643741  0.674793  0.658901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators=100,\n",
    "                                   criterion = 'entropy')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "model_results2=pd.DataFrame([['Random Forest n=100',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "results= results.append(model_results2,ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X=X_train,\n",
    "                             y=y_train, cv= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.63 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier Accuracy: %0.2f (+/- %0.2f)\" % (accuracies.mean(),accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1,5,10],\n",
    "              'min_samples_split': [2,5,10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 825.32 Seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6329763417762478,\n",
       " {'bootstrap': True,\n",
       "  'criterion': 'entropy',\n",
       "  'max_depth': None,\n",
       "  'max_features': 5,\n",
       "  'min_samples_split': 5})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 247.50 Seconds\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [3,5,7],\n",
    "              'min_samples_split': [3,5,7],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"entropy\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6366070906446998,\n",
       " {'bootstrap': True,\n",
       "  'criterion': 'entropy',\n",
       "  'max_depth': None,\n",
       "  'max_features': 7,\n",
       "  'min_samples_split': 5})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 240.94 Seconds\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [3,5,7],\n",
    "              'min_samples_split': [6,7,8],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"entropy\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6357692967443384,\n",
       " {'bootstrap': True,\n",
       "  'criterion': 'entropy',\n",
       "  'max_depth': None,\n",
       "  'max_features': 7,\n",
       "  'min_samples_split': 7})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Model  Accuracy  Precision    Recall  \\\n",
      "0               Linear Regression(Lasso)  0.563372   0.577844  0.700726   \n",
      "1                           SVM (Linear)  0.568398   0.578536  0.729772   \n",
      "2                              SVM (rbf)  0.592686   0.607519  0.687241   \n",
      "3                    Random Forest n=100  0.623953   0.643741  0.674793   \n",
      "4  Random Forest (n=100, GSx2 + ENTROPY)  0.636795   0.653151  0.693465   \n",
      "\n",
      "   F1 Score  \n",
      "0  0.633380  \n",
      "1  0.645413  \n",
      "2  0.644926  \n",
      "3  0.658901  \n",
      "4  0.672704  \n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "model_results2=pd.DataFrame([['Random Forest (n=100, GSx3 + ENTROPY)',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "results= results.append(model_results2,ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 627.18 Seconds\n",
      "Took 186.70 Seconds\n",
      "Took 165.24 Seconds\n",
      "                                   Model  Accuracy  Precision    Recall  \\\n",
      "0               Linear Regression(Lasso)  0.563372   0.577844  0.700726   \n",
      "1                           SVM (Linear)  0.568398   0.578536  0.729772   \n",
      "2                              SVM (rbf)  0.592686   0.607519  0.687241   \n",
      "3                    Random Forest n=100  0.623953   0.643741  0.674793   \n",
      "4  Random Forest (n=100, GSx2 + ENTROPY)  0.636795   0.653151  0.693465   \n",
      "5     Random Forest (n=100, GSx3 + GINI)  0.623953   0.642612  0.678942   \n",
      "\n",
      "   F1 Score  \n",
      "0  0.633380  \n",
      "1  0.645413  \n",
      "2  0.644926  \n",
      "3  0.658901  \n",
      "4  0.672704  \n",
      "5  0.660277  \n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1,5,10],\n",
    "              'min_samples_split': [2,5,10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters\n",
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [3,5,7],\n",
    "              'min_samples_split': [3,5,7],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters\n",
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [3,5,7],\n",
    "              'min_samples_split': [6,7,8],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "t1=time.time()\n",
    "print(\"Took %0.2f Seconds\" % (t1-t0))\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy,rf_best_parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "model_results2=pd.DataFrame([['Random Forest (n=100, GSx3 + GINI)',acc,prec,rec,f1]],\n",
    "            columns =['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "results= results.append(model_results2,ignore_index=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Final Results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat([y_test,users], axis = 1).dropna()\n",
    "final_results['predictions'] = y_pred\n",
    "final_results = final_results[['entry_id','e_signed','predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>e_signed</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6493191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8908605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6889184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9375601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8515555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17881</th>\n",
       "      <td>5028251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17888</th>\n",
       "      <td>8958068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17890</th>\n",
       "      <td>3605941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17901</th>\n",
       "      <td>1807355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>1498559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3582 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entry_id  e_signed  predictions\n",
       "8       6493191       1.0            0\n",
       "9       8908605       1.0            1\n",
       "12      6889184       1.0            1\n",
       "16      9375601       0.0            1\n",
       "18      8515555       1.0            1\n",
       "...         ...       ...          ...\n",
       "17881   5028251       1.0            1\n",
       "17888   8958068       0.0            0\n",
       "17890   3605941       0.0            1\n",
       "17901   1807355       0.0            0\n",
       "17907   1498559       1.0            1\n",
       "\n",
       "[3582 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
